{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a48d388-8380-4ddc-8932-b3e23728eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following tutorials to test and work with CNNs and Pytorch functions for practice\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2b34a9-f891-447b-8c03-2288c9f1b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #transforming rgb into -1 to 1 to train faster\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707c049d-cbe7-4f3c-b3c2-8d69269d6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root = './data', train = True, transform = transform, download = True)\n",
    "test_data = torchvision.datasets.CIFAR10(root = './data', train = False, transform = transform, download = True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle = True, num_workers = 2) #each step 32 images and 32 labels\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 32, shuffle = True, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d54dfb-540f-4d84-b055-e2fc6560294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea10605-b340-4d39-8daa-c5c18eb311bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size() #3 channels, 32 by 32 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e339648f-0d0b-450c-9b26-3e02c159f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46681500-4e00-4d54-abd2-a57731e11e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convulational layers\n",
    "        self.conv1 = nn.Conv2d(3, 12, 5) #5 times 5 kernal moving across features producing 12 feature maps\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 12, 14, 12\n",
    "        self.conv2 = nn.Conv2d(12, 24, 5) #14 - 5 /1 = 9 +1 = 10\n",
    "\n",
    "        #fully connected dense layers\n",
    "        self.fc1 = nn.Linear(24 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) #fed through a relu activation funct\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) #flatten into a single vector per image\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c10eb93-f2a3-4412-b2bb-b85dfab664c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4989aa-8c6b-49ff-a7b4-01b0d3a963ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0...\n",
      "Loss: 2.2106\n",
      "Training epoch 1...\n",
      "Loss: 1.7424\n",
      "Training epoch 2...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40):\n",
    "    print(f'Training epoch {epoch}...')\n",
    "\n",
    "    running_loss = 0.0 #cumulative loss for this epoch\n",
    "    \n",
    "    for i, data in enumerate(train_loader): #go over mini bacthes\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs) #forward pass\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward() #backward pass\n",
    "        optimizer.step() #udpdate the weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0dd19-61f4-4e67-a1aa-65676e696d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'trained_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e4c3c-3d99-40d8-8d01-a6eafc72675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNet()\n",
    "net.load_state_dict(torch.load('trained_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c8bf07-ddb9-4d1a-a36f-ce2971d7607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad(): #turn off autograd for now\n",
    "    for data in test_loader: #loop over the mini-batches\n",
    "        images, labels = data\n",
    "        outputs = net(images) #forward pass\n",
    "        _, predicted = torch.max(outputs, 1) #take the index of the larget logit across the dimention \n",
    "        total += labels.size(0) #add batch size to total\n",
    "        correct += (predicted == labels).sum().item() #count batches and element wise comparision\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a94f45-2e0f-4397-9154-6ba082a6cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 32                    \n",
    "image, true_label = test_data[img_idx]\n",
    "\n",
    "input_tensor = image.unsqueeze(0)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    logits = net(input_tensor)               # forward pass\n",
    "    pred_idx = logits.argmax(dim=1).item()   # get class with highest score\n",
    "\n",
    "pred_label = class_names[pred_idx]\n",
    "true_label_name = class_names[true_label]\n",
    "\n",
    "print(f\"Model prediction : {pred_label}\")\n",
    "print(f\"Ground truth     : {true_label_name}\")\n",
    "\n",
    "img_to_show = image * 0.5 + 0.5              # put pixels back into [0,1]\n",
    "plt.imshow(img_to_show.permute(1, 2, 0))     # C×H×W ➜ H×W×C for matplotlib\n",
    "plt.title(f\"Predicted: {pred_label} | True: {true_label_name}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
